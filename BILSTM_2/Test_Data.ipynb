{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqBgvkqGbvfl",
        "outputId": "06243ed9-1489-44dd-c59f-673c74ec5cf7"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model loaded successfully!\n",
            "✅ Test data regenerated and saved.\n",
            "\n",
            "📊 Model Evaluation Metrics:\n",
            "✅ Test Accuracy  : 0.8353\n",
            "✅ Test Precision : 0.8976\n",
            "✅ Test Recall    : 0.8718\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 193ms/step\n"
          ]
        }
      ],
      "source": [
        "# 🚀 Load everything, evaluate the model, and plot confusion matrix + ROC\n",
        "# -----------------------------------------------\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Install required packages (only once per session)\n",
        "!pip install mne tensorflow seaborn --quiet\n",
        "\n",
        "# Step 3: Import required libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Step 4: Load the trained model from Drive\n",
        "model = load_model('/content/drive/MyDrive/EEG_Siena_Seizure_Data/final_seizure_model.h5')\n",
        "print(\"✅ Model loaded successfully!\")\n",
        "\n",
        "# 🧠 Redo preprocessing to regenerate X_test and Y_test\n",
        "\n",
        "# Constants\n",
        "BASE_DATA_PATH = '/content/drive/MyDrive/EEG_Siena_Seizure_Data/edf_files/'\n",
        "ANNOTATION_BASE_PATH = '/content/drive/MyDrive/EEG_Siena_Seizure_Data/textfile/'\n",
        "CHUNK_SIZE_SECONDS = 5\n",
        "SAMPLING_RATE = 256\n",
        "\n",
        "import os\n",
        "import mne\n",
        "\n",
        "def time_str_to_seconds(t_str):\n",
        "    h, m, s = map(int, t_str.split('.'))\n",
        "    return h * 3600 + m * 60 + s\n",
        "\n",
        "def load_edf(file_path):\n",
        "    raw = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n",
        "    raw.resample(SAMPLING_RATE)\n",
        "    return raw\n",
        "\n",
        "def load_seizure_times(annotation_path):\n",
        "    times = []\n",
        "    reg_start = None\n",
        "    with open(annotation_path, 'r') as f:\n",
        "        for line in f:\n",
        "            if 'Registration start time:' in line:\n",
        "                reg_start = time_str_to_seconds(line.strip().split(': ')[1])\n",
        "            elif 'Seizure start time:' in line and reg_start is not None:\n",
        "                seizure_time = time_str_to_seconds(line.strip().split(': ')[1])\n",
        "                times.append(seizure_time - reg_start)\n",
        "    return times\n",
        "\n",
        "def segment_eeg(raw, start, end):\n",
        "    sfreq = int(raw.info['sfreq'])\n",
        "    data = raw.get_data()\n",
        "    chunks = []\n",
        "    for t in range(start, end - CHUNK_SIZE_SECONDS + 1, CHUNK_SIZE_SECONDS):\n",
        "        s, e = t * sfreq, (t + CHUNK_SIZE_SECONDS) * sfreq\n",
        "        chunk = data[:, s:e]\n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            norm = (chunk - np.mean(chunk, axis=1, keepdims=True)) / np.std(chunk, axis=1, keepdims=True)\n",
        "            norm = np.nan_to_num(norm)\n",
        "        chunks.append(norm.T)\n",
        "    return chunks\n",
        "\n",
        "def create_dataset_from_file(file_name):\n",
        "    raw = load_edf(os.path.join(BASE_DATA_PATH, file_name))\n",
        "    annotation_file = 'Seizures-list-' + file_name.split('-')[0] + '.txt'\n",
        "    seizure_times = load_seizure_times(os.path.join(ANNOTATION_BASE_PATH, annotation_file))\n",
        "    total_sec = int(raw.n_times / raw.info['sfreq'])\n",
        "    preictal, interictal = [], []\n",
        "    for sz in seizure_times:\n",
        "        preictal.extend(segment_eeg(raw, max(0, sz - 1800), sz))\n",
        "        if sz + 1200 < total_sec:\n",
        "            interictal.extend(segment_eeg(raw, sz + 600, sz + 1200))\n",
        "    return preictal, interictal\n",
        "\n",
        "# Load all files\n",
        "X, Y = [], []\n",
        "edf_files = [f for f in os.listdir(BASE_DATA_PATH) if f.endswith('.edf')]\n",
        "\n",
        "for f in edf_files:\n",
        "    pre, inter = create_dataset_from_file(f)\n",
        "    X.extend(pre)\n",
        "    Y.extend([1]*len(pre))\n",
        "    X.extend(inter)\n",
        "    Y.extend([0]*len(inter))\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "# Split into test set again (same as training)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_trainval, X_test, Y_trainval, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=42)\n",
        "\n",
        "# 💾 Save test data for future use\n",
        "np.save('/content/drive/MyDrive/EEG_Siena_Seizure_Data/X_test.npy', X_test)\n",
        "np.save('/content/drive/MyDrive/EEG_Siena_Seizure_Data/Y_test.npy', Y_test)\n",
        "\n",
        "print(\"✅ Test data regenerated and saved.\")\n",
        "\n",
        "\n",
        "# Step 5: Load pre-saved test data (update path if needed)\n",
        "X_test = np.load('/content/drive/MyDrive/EEG_Siena_Seizure_Data/X_test.npy')\n",
        "Y_test = np.load('/content/drive/MyDrive/EEG_Siena_Seizure_Data/Y_test.npy')\n",
        "\n",
        "# Step 6: Define test data generator\n",
        "class EEGDataGenerator(Sequence):\n",
        "    def __init__(self, x, y, batch_size=8):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.batch_size = batch_size\n",
        "        self.indices = np.arange(len(x))\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.x) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_idx = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        return np.array([self.x[i] for i in batch_idx]), np.array([self.y[i] for i in batch_idx])\n",
        "\n",
        "test_generator = EEGDataGenerator(X_test, Y_test)\n",
        "\n",
        "# Step 7: Evaluate the model on test data\n",
        "results = model.evaluate(test_generator, verbose=0)\n",
        "print(\"\\n📊 Model Evaluation Metrics:\")\n",
        "print(f\"✅ Test Accuracy  : {results[1]:.4f}\")\n",
        "print(f\"✅ Test Precision : {results[2]:.4f}\")\n",
        "print(f\"✅ Test Recall    : {results[3]:.4f}\")\n",
        "\n",
        "# Step 8: Predictions and true labels\n",
        "y_prob = model.predict(test_generator).flatten()     # Predicted probabilities\n",
        "y_pred = (y_prob > 0.5).astype(int)                   # Binary predictions\n",
        "y_true = np.concatenate([y for _, y in test_generator])  # True labels\n",
        "\n",
        "# Step 9: Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"🧠 Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 10: ROC Curve & AUC\n",
        "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(fpr, tpr, color='darkorange', label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"📈 ROC Curve\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n🎉 Visualization complete! Use this for report or presentation confidently.\")\n"
      ]
    }
  ]
}