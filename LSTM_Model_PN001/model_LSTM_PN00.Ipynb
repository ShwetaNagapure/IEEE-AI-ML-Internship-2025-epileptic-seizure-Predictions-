{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bfee2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\python312\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\python312\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\python312\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\python312\\lib\\site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\python312\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\python312\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\python312\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\python312\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\python312\\lib\\site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\python312\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\python312\\lib\\site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\python312\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\python312\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\python312\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\python312\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\python312\\lib\\site-packages (from tensorflow) (1.65.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\python312\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\python312\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\python312\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\python312\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\python312\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python312\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\python312\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\python312\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install mne\n",
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12ebb4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from mne.io import read_raw_edf\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1241f4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Admin\\Desktop\\Data_Preprocessing\\data\\PN00-1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 1343999  =      0.000 ...  2624.998 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\1581520723.py:80: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\1581520723.py:80: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\1581520723.py:80: RuntimeWarning: Highpass cutoff frequency 15.91549 is greater than lowpass cutoff frequency 15.0, setting values to 0 and Nyquist.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDF Duration: 2625.00s | Seizure Start: 1143.00s | Preictal Start: 0.00s | Baseline Start: 0.00s\n",
      "PN00-1.edf — Preictal: 38 | Interictal: 60\n",
      "Extracting EDF parameters from C:\\Users\\Admin\\Desktop\\Data_Preprocessing\\data\\PN00-2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 1178623  =      0.000 ...  2301.998 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\1581520723.py:80: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\1581520723.py:80: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\1581520723.py:80: RuntimeWarning: Highpass cutoff frequency 15.91549 is greater than lowpass cutoff frequency 15.0, setting values to 0 and Nyquist.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDF Duration: 2302.00s | Seizure Start: 1220.00s | Preictal Start: 0.00s | Baseline Start: 0.00s\n",
      "PN00-2.edf — Preictal: 40 | Interictal: 60\n",
      "Extracting EDF parameters from C:\\Users\\Admin\\Desktop\\Data_Preprocessing\\data\\PN00-3.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 1284607  =      0.000 ...  2508.998 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\1581520723.py:80: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\1581520723.py:80: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\1581520723.py:80: RuntimeWarning: Highpass cutoff frequency 15.91549 is greater than lowpass cutoff frequency 15.0, setting values to 0 and Nyquist.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDF Duration: 2509.00s | Seizure Start: 765.00s | Preictal Start: 0.00s | Baseline Start: 0.00s\n",
      "PN00-3.edf — Preictal: 25 | Interictal: 60\n",
      "Extracting EDF parameters from C:\\Users\\Admin\\Desktop\\Data_Preprocessing\\data\\PN00-4.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 1076223  =      0.000 ...  2101.998 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\1581520723.py:80: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\1581520723.py:80: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\1581520723.py:80: RuntimeWarning: Highpass cutoff frequency 15.91549 is greater than lowpass cutoff frequency 15.0, setting values to 0 and Nyquist.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDF Duration: 2102.00s | Seizure Start: 1006.00s | Preictal Start: 0.00s | Baseline Start: 0.00s\n",
      "PN00-4.edf — Preictal: 33 | Interictal: 60\n",
      "Extracting EDF parameters from C:\\Users\\Admin\\Desktop\\Data_Preprocessing\\data\\PN00-5.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 1097215  =      0.000 ...  2142.998 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\1581520723.py:80: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\1581520723.py:80: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\1581520723.py:80: RuntimeWarning: Highpass cutoff frequency 15.91549 is greater than lowpass cutoff frequency 15.0, setting values to 0 and Nyquist.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDF Duration: 2143.00s | Seizure Start: 904.00s | Preictal Start: 0.00s | Baseline Start: 0.00s\n",
      "PN00-5.edf — Preictal: 30 | Interictal: 60\n"
     ]
    }
   ],
   "source": [
    "# ===================== Paths & Labels =======================\n",
    "data_path = r\"C:\\Users\\Admin\\Desktop\\Data_Preprocessing\\data\"\n",
    "\n",
    "# Replace this with your real seizure start/end times (wall-clock HH:MM:SS)\n",
    "# Updated Seizure Times and Filenames\n",
    "seizure_files = {\n",
    "    \"PN00-1.edf\": (\"19:58:36\", \"19:59:46\"),\n",
    "    \"PN00-2.edf\": (\"02:38:37\", \"02:39:31\"),\n",
    "    \"PN00-3.edf\": (\"18:28:29\", \"19:29:29\"),\n",
    "    \"PN00-4.edf\": (\"21:08:29\", \"21:09:43\"),\n",
    "    \"PN00-5.edf\": (\"22:37:08\", \"22:38:15\"),\n",
    "}\n",
    "\n",
    "# Updated Baseline Start Times\n",
    "baseline_start_times = {\n",
    "    \"PN00-1.edf\": \"19:39:33\",\n",
    "    \"PN00-2.edf\": \"02:18:17\",\n",
    "    \"PN00-3.edf\": \"18:15:44\",\n",
    "    \"PN00-4.edf\": \"20:51:43\",\n",
    "    \"PN00-5.edf\": \"22:22:04\",\n",
    "}\n",
    "\n",
    "channels_to_use = list(range(18))  # First 18 channels\n",
    "\n",
    "# =============== Time Conversion =====================\n",
    "def relative_seconds(timestr, meas_date):\n",
    "    \"\"\"Convert wall-clock HH:MM:SS to seconds from EDF start.\"\"\"\n",
    "    target = datetime.strptime(timestr, \"%H:%M:%S\").time()\n",
    "    start = meas_date.time()\n",
    "    target_dt = datetime.combine(datetime.today(), target)\n",
    "    start_dt = datetime.combine(datetime.today(), start)\n",
    "    return (target_dt - start_dt).total_seconds()\n",
    "\n",
    "# =============== Window Extraction ====================\n",
    "def extract_windows(raw, seizure_start, seizure_end, baseline_start):\n",
    "    window_size = 30  # seconds\n",
    "    sampling_rate = int(raw.info['sfreq'])\n",
    "    total_duration = raw.times[-1]\n",
    "\n",
    "    # Use maximum possible preictal window\n",
    "    max_preictal_duration = seizure_start\n",
    "    preictal_window = min(30 * 60, max_preictal_duration)\n",
    "    preictal_start = seizure_start - preictal_window\n",
    "\n",
    "    print(f\"EDF Duration: {total_duration:.2f}s | Seizure Start: {seizure_start:.2f}s | Preictal Start: {preictal_start:.2f}s | Baseline Start: {baseline_start:.2f}s\")\n",
    "\n",
    "    if seizure_start > total_duration:\n",
    "        print(\"[SKIP] Seizure start is after end of recording.\")\n",
    "        return [], []\n",
    "\n",
    "    if baseline_start + 30 * 60 > total_duration:\n",
    "        print(\"[SKIP] Baseline + 30min is beyond recording duration.\")\n",
    "        return [], []\n",
    "\n",
    "    try:\n",
    "        preictal_data = raw.copy().crop(tmin=preictal_start, tmax=seizure_start).get_data()[channels_to_use]\n",
    "        interictal_data = raw.copy().crop(tmin=baseline_start, tmax=baseline_start + 30 * 60).get_data()[channels_to_use]\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Cropping failed: {e}\")\n",
    "        return [], []\n",
    "\n",
    "    def segment(data):\n",
    "        n_samples = data.shape[1]\n",
    "        samples_per_win = sampling_rate * window_size\n",
    "        segments = []\n",
    "        for start in range(0, n_samples - samples_per_win, samples_per_win):\n",
    "            segment = data[:, start:start + samples_per_win]\n",
    "            segments.append(segment)\n",
    "        return segments\n",
    "\n",
    "    return segment(preictal_data), segment(interictal_data)\n",
    "\n",
    "\n",
    "# =============== Data Processing ====================\n",
    "X, y = [], []\n",
    "\n",
    "for file, (sz_start, sz_end) in seizure_files.items():\n",
    "    reg_start = baseline_start_times[file]\n",
    "    file_path = os.path.join(data_path, file)\n",
    "    raw = read_raw_edf(file_path, preload=True)\n",
    "    meas_date = raw.info['meas_date']\n",
    "    if meas_date is None:\n",
    "        print(f\"[WARNING] {file} has no meas_date metadata — skipping.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        sz_start_sec = relative_seconds(sz_start, meas_date)\n",
    "        sz_end_sec = relative_seconds(sz_end, meas_date)\n",
    "        reg_start_sec = relative_seconds(reg_start, meas_date)\n",
    "\n",
    "        preictal, interictal = extract_windows(raw, sz_start_sec, sz_end_sec, reg_start_sec)\n",
    "        print(f\"{file} — Preictal: {len(preictal)} | Interictal: {len(interictal)}\")\n",
    "\n",
    "        X.extend(preictal)\n",
    "        y.extend([1] * len(preictal))\n",
    "\n",
    "        X.extend(interictal)\n",
    "        y.extend([0] * len(interictal))\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {file} — {e}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc8fc99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing PN00-1.edf\n",
      "Extracting EDF parameters from C:\\Users\\Admin\\Desktop\\Data_Preprocessing\\data\\PN00-1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 1343999  =      0.000 ...  2624.998 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\3832845794.py:8: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\3832845794.py:8: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\3832845794.py:8: RuntimeWarning: Highpass cutoff frequency 15.91549 is greater than lowpass cutoff frequency 15.0, setting values to 0 and Nyquist.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDF Duration: 2625.00s | Seizure Start: 1143.00s | Preictal Start: 0.00s | Baseline Start: 0.00s\n",
      "PN00-1.edf — Preictal: 38 | Interictal: 60\n",
      "[ERROR] PN00-1.edf — 'numpy.ndarray' object has no attribute 'extend'\n",
      "\n",
      "Processing PN00-2.edf\n",
      "Extracting EDF parameters from C:\\Users\\Admin\\Desktop\\Data_Preprocessing\\data\\PN00-2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 1178623  =      0.000 ...  2301.998 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\3832845794.py:8: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\3832845794.py:8: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\3832845794.py:8: RuntimeWarning: Highpass cutoff frequency 15.91549 is greater than lowpass cutoff frequency 15.0, setting values to 0 and Nyquist.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDF Duration: 2302.00s | Seizure Start: 1220.00s | Preictal Start: 0.00s | Baseline Start: 0.00s\n",
      "PN00-2.edf — Preictal: 40 | Interictal: 60\n",
      "[ERROR] PN00-2.edf — 'numpy.ndarray' object has no attribute 'extend'\n",
      "\n",
      "Processing PN00-3.edf\n",
      "Extracting EDF parameters from C:\\Users\\Admin\\Desktop\\Data_Preprocessing\\data\\PN00-3.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 1284607  =      0.000 ...  2508.998 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\3832845794.py:8: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\3832845794.py:8: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\3832845794.py:8: RuntimeWarning: Highpass cutoff frequency 15.91549 is greater than lowpass cutoff frequency 15.0, setting values to 0 and Nyquist.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDF Duration: 2509.00s | Seizure Start: 765.00s | Preictal Start: 0.00s | Baseline Start: 0.00s\n",
      "PN00-3.edf — Preictal: 25 | Interictal: 60\n",
      "[ERROR] PN00-3.edf — 'numpy.ndarray' object has no attribute 'extend'\n",
      "\n",
      "Processing PN00-4.edf\n",
      "Extracting EDF parameters from C:\\Users\\Admin\\Desktop\\Data_Preprocessing\\data\\PN00-4.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 1076223  =      0.000 ...  2101.998 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\3832845794.py:8: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\3832845794.py:8: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\3832845794.py:8: RuntimeWarning: Highpass cutoff frequency 15.91549 is greater than lowpass cutoff frequency 15.0, setting values to 0 and Nyquist.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDF Duration: 2102.00s | Seizure Start: 1006.00s | Preictal Start: 0.00s | Baseline Start: 0.00s\n",
      "PN00-4.edf — Preictal: 33 | Interictal: 60\n",
      "[ERROR] PN00-4.edf — 'numpy.ndarray' object has no attribute 'extend'\n",
      "\n",
      "Processing PN00-5.edf\n",
      "Extracting EDF parameters from C:\\Users\\Admin\\Desktop\\Data_Preprocessing\\data\\PN00-5.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 1097215  =      0.000 ...  2142.998 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\3832845794.py:8: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\3832845794.py:8: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\3832845794.py:8: RuntimeWarning: Highpass cutoff frequency 15.91549 is greater than lowpass cutoff frequency 15.0, setting values to 0 and Nyquist.\n",
      "  raw = read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDF Duration: 2143.00s | Seizure Start: 904.00s | Preictal Start: 0.00s | Baseline Start: 0.00s\n",
      "PN00-5.edf — Preictal: 30 | Interictal: 60\n",
      "[ERROR] PN00-5.edf — 'numpy.ndarray' object has no attribute 'extend'\n"
     ]
    }
   ],
   "source": [
    "summary = []  # ✅ Initialize\n",
    "\n",
    "for file, (sz_start, sz_end) in seizure_files.items():\n",
    "    print(f\"\\nProcessing {file}\")\n",
    "    reg_start = baseline_start_times[file]\n",
    "    file_path = os.path.join(data_path, file)\n",
    "    \n",
    "    raw = read_raw_edf(file_path, preload=True)\n",
    "\n",
    "    meas_date = raw.info['meas_date']\n",
    "    if meas_date is None:\n",
    "        print(f\"[WARNING] {file} has no meas_date metadata — skipping.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        sz_start_sec = relative_seconds(sz_start, meas_date)\n",
    "        sz_end_sec = relative_seconds(sz_end, meas_date)\n",
    "        reg_start_sec = relative_seconds(reg_start, meas_date)\n",
    "\n",
    "        preictal, interictal = extract_windows(raw, sz_start_sec, sz_end_sec, reg_start_sec)\n",
    "        print(f\"{file} — Preictal: {len(preictal)} | Interictal: {len(interictal)}\")\n",
    "\n",
    "        X.extend(preictal)\n",
    "        y.extend([1] * len(preictal))\n",
    "\n",
    "        X.extend(interictal)\n",
    "        y.extend([0] * len(interictal))\n",
    "\n",
    "        # ✅ Append summary\n",
    "        summary.append({\n",
    "            \"file\": file,\n",
    "            \"preictal_segments\": len(preictal),\n",
    "            \"interictal_segments\": len(interictal),\n",
    "            \"seizure_start_sec\": sz_start_sec,\n",
    "            \"baseline_start_sec\": reg_start_sec\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {file} — {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c76dc9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(summary).to_csv(\"segmentation_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "416bc4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape for LSTM: (466, 15360, 18)\n"
     ]
    }
   ],
   "source": [
    "# (samples, channels, time_steps) → (samples, time_steps, channels)\n",
    "X = np.transpose(X, (0, 2, 1))  # Now shape is (samples, 30*sampling_rate, channels)\n",
    "print(\"X shape for LSTM:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b6874f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60122f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Convert numpy to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)  # shape: (samples, time_steps, channels)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Dataset and dataloader\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define LSTM model\n",
    "class SeizureLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64):\n",
    "        super(SeizureLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        out = self.fc(h_n[-1])\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "model = SeizureLSTM(input_size=X.shape[2])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f682b40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6752\n",
      "Epoch 2, Loss: 0.7059\n",
      "Epoch 3, Loss: 0.6168\n",
      "Epoch 4, Loss: 0.6046\n",
      "Epoch 5, Loss: 0.6695\n",
      "Epoch 6, Loss: 0.6692\n",
      "Epoch 7, Loss: 0.7051\n",
      "Epoch 8, Loss: 0.7010\n",
      "Epoch 9, Loss: 0.6385\n",
      "Epoch 10, Loss: 0.7320\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        outputs = model(batch_X).squeeze()\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d8beac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6438\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        predicted = (outputs >= 0.5).float()\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4d5a1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as seizure_lstm_model.pth\n"
     ]
    }
   ],
   "source": [
    "# ======================= SAVE MODEL =======================\n",
    "torch.save(model.state_dict(), \"seizure_lstm_model.pth\")\n",
    "print(\"Model saved as seizure_lstm_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7930a75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeizureLSTM(\n",
       "  (lstm): LSTM(18, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-initialize the model class with same input_size and architecture\n",
    "loaded_model = SeizureLSTM(input_size=X.shape[2])\n",
    "loaded_model.load_state_dict(torch.load(\"seizure_lstm_model.pth\"))\n",
    "loaded_model.eval()  # Set to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25f85f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeizureLSTM(\n",
       "  (lstm): LSTM(18, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rebuild the LSTM Class & Load Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Same architecture as used in training\n",
    "class SeizureLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64):\n",
    "        super(SeizureLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        out = self.fc(h_n[-1])\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "# Initialize and load trained weights\n",
    "model = SeizureLSTM(input_size=18)\n",
    "model.load_state_dict(torch.load(\"seizure_lstm_model.pth\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "960871cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Admin\\Desktop\\Data_Preprocessing\\data\\PN05-2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 4733439  =      0.000 ...  9244.998 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\900009265.py:5: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(r\"C:\\Users\\Admin\\Desktop\\Data_Preprocessing\\data\\PN05-2.edf\", preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\900009265.py:5: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  raw = mne.io.read_raw_edf(r\"C:\\Users\\Admin\\Desktop\\Data_Preprocessing\\data\\PN05-2.edf\", preload=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14588\\900009265.py:5: RuntimeWarning: Highpass cutoff frequency 15.91549 is greater than lowpass cutoff frequency 15.0, setting values to 0 and Nyquist.\n",
      "  raw = mne.io.read_raw_edf(r\"C:\\Users\\Admin\\Desktop\\Data_Preprocessing\\data\\PN05-2.edf\", preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "# Load the EDF file\n",
    "raw = mne.io.read_raw_edf(r\"C:\\Users\\Admin\\Desktop\\Data_Preprocessing\\data\\PN05-2.edf\", preload=True)\n",
    "\n",
    "# Get the first 30 seconds of selected 18 channels\n",
    "sfreq = int(raw.info['sfreq'])  # e.g., 256 Hz\n",
    "window_sec = 30\n",
    "n_samples = sfreq * window_sec\n",
    "\n",
    "# Select only the first 18 channels (used during training)\n",
    "raw.pick_channels(raw.ch_names[:18])  # or channels_to_use if predefined\n",
    "\n",
    "# Get data from the first 30 seconds\n",
    "data, _ = raw[:, :n_samples]  # shape: (channels, time_steps)\n",
    "data = data.T[np.newaxis, ...]  # shape: (1, time_steps, channels)\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "input_tensor = torch.tensor(data, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b4beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Seizure Probability: 0.3624\n",
      "✅ Normal brain activity (Interictal)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input_tensor).item()\n",
    "    print(f\"Predicted Seizure Probability: {output:.4f}\")\n",
    "    \n",
    "    if output >= 0.5:\n",
    "        print(\" Seizure likely within 30 minutes (Preictal)\")\n",
    "    else:\n",
    "        print(\" Normal brain activity (Interictal)\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeefd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 — Count: 300\n",
      "Class 1 — Count: 166\n"
     ]
    }
   ],
   "source": [
    "#Class 0 (Interictal): 300 samples\n",
    "#Class 1 (Preictal): 166 samples\n",
    "import numpy as np\n",
    "\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"Class {label} — Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c85b201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
